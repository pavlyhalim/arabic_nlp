{
  "model": "en",
  "best_config": {
    "model_name": "bert-base-uncased",
    "train_lang": "en",
    "learning_rate": 1e-05,
    "seed": 45,
    "val_accuracy": 0.5724381625441696,
    "test_accuracy": 0.625
  },
  "all_results": [
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.5477031802120141,
      "val_f1": 0.5376943385486995,
      "val_precision": 0.5332730488078645,
      "val_recall": 0.5477031802120141,
      "test_accuracy": 0.625,
      "test_f1": 0.626131084597189,
      "test_precision": 0.6382102325650713,
      "test_recall": 0.625,
      "learning_rate": 1e-05,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.5512367491166078,
      "val_f1": 0.541394024284312,
      "val_precision": 0.5371619983999968,
      "val_recall": 0.5512367491166078,
      "test_accuracy": 0.6081081081081081,
      "test_f1": 0.6037659041537525,
      "test_precision": 0.6032841277237829,
      "test_recall": 0.6081081081081081,
      "learning_rate": 1e-05,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.5618374558303887,
      "val_f1": 0.5383552669854063,
      "val_precision": 0.5546361003205467,
      "val_recall": 0.5618374558303887,
      "test_accuracy": 0.6013513513513513,
      "test_f1": 0.5818267646954717,
      "test_precision": 0.6162357073112222,
      "test_recall": 0.6013513513513513,
      "learning_rate": 1e-05,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.5724381625441696,
      "val_f1": 0.5594754174534353,
      "val_precision": 0.5522822395119621,
      "val_recall": 0.5724381625441696,
      "test_accuracy": 0.625,
      "test_f1": 0.6177703318807612,
      "test_precision": 0.6230282594412248,
      "test_recall": 0.625,
      "learning_rate": 1e-05,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.5512367491166078,
      "val_f1": 0.5430137217729974,
      "val_precision": 0.5365740578274354,
      "val_recall": 0.5512367491166078,
      "test_accuracy": 0.6351351351351351,
      "test_f1": 0.6266783728014443,
      "test_precision": 0.63275750508576,
      "test_recall": 0.6351351351351351,
      "learning_rate": 1e-05,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.4840989399293286,
      "val_f1": 0.3767438777205121,
      "val_precision": 0.3565583743881286,
      "val_recall": 0.4840989399293286,
      "test_accuracy": 0.4358108108108108,
      "test_f1": 0.31812273160834525,
      "test_precision": 0.27340403189917756,
      "test_recall": 0.4358108108108108,
      "learning_rate": 1e-06,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.49469964664310956,
      "val_f1": 0.4036015368478192,
      "val_precision": 0.4550481850305172,
      "val_recall": 0.49469964664310956,
      "test_accuracy": 0.47635135135135137,
      "test_f1": 0.37575112419964274,
      "test_precision": 0.39838823941941237,
      "test_recall": 0.47635135135135137,
      "learning_rate": 1e-06,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.48056537102473496,
      "val_f1": 0.4268038261830261,
      "val_precision": 0.45938306279065005,
      "val_recall": 0.48056537102473496,
      "test_accuracy": 0.5101351351351351,
      "test_f1": 0.44545683457941404,
      "test_precision": 0.4448379589515845,
      "test_recall": 0.5101351351351351,
      "learning_rate": 1e-06,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.4876325088339223,
      "val_f1": 0.3709824075952902,
      "val_precision": 0.3827537236659659,
      "val_recall": 0.4876325088339223,
      "test_accuracy": 0.44256756756756754,
      "test_f1": 0.32056127596879946,
      "test_precision": 0.27914120642381507,
      "test_recall": 0.44256756756756754,
      "learning_rate": 1e-06,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.4876325088339223,
      "val_f1": 0.40359156952895525,
      "val_precision": 0.3947192117886294,
      "val_recall": 0.4876325088339223,
      "test_accuracy": 0.4594594594594595,
      "test_f1": 0.37911367249602546,
      "test_precision": 0.4244851163455815,
      "test_recall": 0.4594594594594595,
      "learning_rate": 1e-06,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.3215547703180212,
      "val_f1": 0.1628784641980827,
      "val_precision": 0.2252650176678445,
      "val_recall": 0.3215547703180212,
      "test_accuracy": 0.30743243243243246,
      "test_f1": 0.14654810250665173,
      "test_precision": 0.09620334620334621,
      "test_recall": 0.30743243243243246,
      "learning_rate": 1e-07,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.35335689045936397,
      "val_f1": 0.22154898987937857,
      "val_precision": 0.23155707187631155,
      "val_recall": 0.35335689045936397,
      "test_accuracy": 0.34459459459459457,
      "test_f1": 0.21687012312012313,
      "test_precision": 0.22581780949747704,
      "test_recall": 0.34459459459459457,
      "learning_rate": 1e-07,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.22968197879858657,
      "val_f1": 0.12298529196685441,
      "val_precision": 0.29945901352101156,
      "val_recall": 0.22968197879858657,
      "test_accuracy": 0.26013513513513514,
      "test_f1": 0.13375748045629351,
      "test_precision": 0.3443087318087318,
      "test_recall": 0.26013513513513514,
      "learning_rate": 1e-07,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.1696113074204947,
      "val_f1": 0.09740552506631457,
      "val_precision": 0.14492761883050267,
      "val_recall": 0.1696113074204947,
      "test_accuracy": 0.19256756756756757,
      "test_f1": 0.10882083382083381,
      "test_precision": 0.2266457913009637,
      "test_recall": 0.19256756756756757,
      "learning_rate": 1e-07,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "en",
      "val_accuracy": 0.2049469964664311,
      "val_f1": 0.10789025944611794,
      "val_precision": 0.07324495326965395,
      "val_recall": 0.2049469964664311,
      "test_accuracy": 0.17905405405405406,
      "test_f1": 0.10176966721592744,
      "test_precision": 0.07144630090980775,
      "test_recall": 0.17905405405405406,
      "learning_rate": 1e-07,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_en_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.5408163265306123,
      "val_f1": 0.5142521564720423,
      "val_precision": 0.5366130799981599,
      "val_recall": 0.5408163265306123,
      "test_accuracy": 0.48058252427184467,
      "test_f1": 0.4657660823734941,
      "test_precision": 0.45891894490997437,
      "test_recall": 0.48058252427184467,
      "learning_rate": 1e-05,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.5255102040816326,
      "val_f1": 0.5069037252837992,
      "val_precision": 0.5878031035286659,
      "val_recall": 0.5255102040816326,
      "test_accuracy": 0.46116504854368934,
      "test_f1": 0.44585533951494116,
      "test_precision": 0.5174995787847557,
      "test_recall": 0.46116504854368934,
      "learning_rate": 1e-05,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.5204081632653061,
      "val_f1": 0.4945794620549904,
      "val_precision": 0.48079730588405784,
      "val_recall": 0.5204081632653061,
      "test_accuracy": 0.4563106796116505,
      "test_f1": 0.4321856283514996,
      "test_precision": 0.42748487549615016,
      "test_recall": 0.4563106796116505,
      "learning_rate": 1e-05,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.5612244897959183,
      "val_f1": 0.5527234238893123,
      "val_precision": 0.5770375033130135,
      "val_recall": 0.5612244897959183,
      "test_accuracy": 0.46601941747572817,
      "test_f1": 0.46425682962698545,
      "test_precision": 0.4745731028561892,
      "test_recall": 0.46601941747572817,
      "learning_rate": 1e-05,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.5153061224489796,
      "val_f1": 0.49845159204076683,
      "val_precision": 0.5614660215406484,
      "val_recall": 0.5153061224489796,
      "test_accuracy": 0.48058252427184467,
      "test_f1": 0.47027722246575254,
      "test_precision": 0.5140374619986271,
      "test_recall": 0.48058252427184467,
      "learning_rate": 1e-05,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.4489795918367347,
      "val_f1": 0.37809355908081954,
      "val_precision": 0.3748724489795919,
      "val_recall": 0.4489795918367347,
      "test_accuracy": 0.4368932038834951,
      "test_f1": 0.3910478412367735,
      "test_precision": 0.3702977452558972,
      "test_recall": 0.4368932038834951,
      "learning_rate": 1e-06,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.4336734693877551,
      "val_f1": 0.3754321602915828,
      "val_precision": 0.4149659863945578,
      "val_recall": 0.4336734693877551,
      "test_accuracy": 0.4077669902912621,
      "test_f1": 0.36080611826034975,
      "test_precision": 0.360634511119948,
      "test_recall": 0.4077669902912621,
      "learning_rate": 1e-06,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.40816326530612246,
      "val_f1": 0.3157703621989336,
      "val_precision": 0.31908631584501934,
      "val_recall": 0.40816326530612246,
      "test_accuracy": 0.3737864077669903,
      "test_f1": 0.2855251544571933,
      "test_precision": 0.23767914932963477,
      "test_recall": 0.3737864077669903,
      "learning_rate": 1e-06,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.413265306122449,
      "val_f1": 0.31404670409928953,
      "val_precision": 0.2711841480778358,
      "val_recall": 0.413265306122449,
      "test_accuracy": 0.3883495145631068,
      "test_f1": 0.3177455343854109,
      "test_precision": 0.2767636858285427,
      "test_recall": 0.3883495145631068,
      "learning_rate": 1e-06,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.40816326530612246,
      "val_f1": 0.30840918527035227,
      "val_precision": 0.2886938134751546,
      "val_recall": 0.40816326530612246,
      "test_accuracy": 0.3737864077669903,
      "test_f1": 0.3025297346401077,
      "test_precision": 0.28171675469392937,
      "test_recall": 0.3737864077669903,
      "learning_rate": 1e-06,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.32142857142857145,
      "val_f1": 0.15637065637065636,
      "val_precision": 0.10331632653061225,
      "val_recall": 0.32142857142857145,
      "test_accuracy": 0.3300970873786408,
      "test_f1": 0.1638438097937779,
      "test_precision": 0.10896408709586201,
      "test_recall": 0.3300970873786408,
      "learning_rate": 1e-07,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.34183673469387754,
      "val_f1": 0.1956052262174711,
      "val_precision": 0.15216836734693878,
      "val_recall": 0.34183673469387754,
      "test_accuracy": 0.35436893203883496,
      "test_f1": 0.20488668941693006,
      "test_precision": 0.1587422455497841,
      "test_recall": 0.35436893203883496,
      "learning_rate": 1e-07,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.30612244897959184,
      "val_f1": 0.1819358631689539,
      "val_precision": 0.13023651018849097,
      "val_recall": 0.30612244897959184,
      "test_accuracy": 0.25728155339805825,
      "test_f1": 0.14921405455386036,
      "test_precision": 0.10508280982295831,
      "test_recall": 0.25728155339805825,
      "learning_rate": 1e-07,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.32142857142857145,
      "val_f1": 0.1907459976471792,
      "val_precision": 0.16595547309833025,
      "val_recall": 0.32142857142857145,
      "test_accuracy": 0.34951456310679613,
      "test_f1": 0.22476831545880616,
      "test_precision": 0.46851426040881317,
      "test_recall": 0.34951456310679613,
      "learning_rate": 1e-07,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ar",
      "val_accuracy": 0.25,
      "val_f1": 0.13251231527093596,
      "val_precision": 0.12142857142857141,
      "val_recall": 0.25,
      "test_accuracy": 0.2766990291262136,
      "test_f1": 0.14493620645811547,
      "test_precision": 0.10528348441774392,
      "test_recall": 0.2766990291262136,
      "learning_rate": 1e-07,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_ar_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.5100671140939598,
      "val_f1": 0.4416169804221935,
      "val_precision": 0.401062782860445,
      "val_recall": 0.5100671140939598,
      "test_accuracy": 0.4171779141104294,
      "test_f1": 0.3563100446101145,
      "test_precision": 0.36165340329629103,
      "test_recall": 0.4171779141104294,
      "learning_rate": 1e-05,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.5234899328859061,
      "val_f1": 0.497759489563645,
      "val_precision": 0.5132896559071056,
      "val_recall": 0.5234899328859061,
      "test_accuracy": 0.44171779141104295,
      "test_f1": 0.4099025532729052,
      "test_precision": 0.42618703078825776,
      "test_recall": 0.44171779141104295,
      "learning_rate": 1e-05,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.5436241610738255,
      "val_f1": 0.494226432600453,
      "val_precision": 0.5106888265726637,
      "val_recall": 0.5436241610738255,
      "test_accuracy": 0.44171779141104295,
      "test_f1": 0.40355827369990005,
      "test_precision": 0.46039324900699813,
      "test_recall": 0.44171779141104295,
      "learning_rate": 1e-05,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.5033557046979866,
      "val_f1": 0.4711423144410797,
      "val_precision": 0.46970724784104295,
      "val_recall": 0.5033557046979866,
      "test_accuracy": 0.4601226993865031,
      "test_f1": 0.42265732713132254,
      "test_precision": 0.48359374754585516,
      "test_recall": 0.4601226993865031,
      "learning_rate": 1e-05,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.5234899328859061,
      "val_f1": 0.4953710948963855,
      "val_precision": 0.5016599242403026,
      "val_recall": 0.5234899328859061,
      "test_accuracy": 0.4601226993865031,
      "test_f1": 0.43743475719180097,
      "test_precision": 0.5236243847789384,
      "test_recall": 0.4601226993865031,
      "learning_rate": 1e-05,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.37583892617449666,
      "val_f1": 0.3440546052135049,
      "val_precision": 0.344806958298452,
      "val_recall": 0.37583892617449666,
      "test_accuracy": 0.3803680981595092,
      "test_f1": 0.33201517561435756,
      "test_precision": 0.32921816552117966,
      "test_recall": 0.3803680981595092,
      "learning_rate": 1e-06,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.4228187919463087,
      "val_f1": 0.37781167710489194,
      "val_precision": 0.3658811458175641,
      "val_recall": 0.4228187919463087,
      "test_accuracy": 0.3987730061349693,
      "test_f1": 0.36357695286774266,
      "test_precision": 0.4020726514724914,
      "test_recall": 0.3987730061349693,
      "learning_rate": 1e-06,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.4697986577181208,
      "val_f1": 0.3992331929178874,
      "val_precision": 0.35940255844268865,
      "val_recall": 0.4697986577181208,
      "test_accuracy": 0.4171779141104294,
      "test_f1": 0.36529379507234966,
      "test_precision": 0.5282455124569885,
      "test_recall": 0.4171779141104294,
      "learning_rate": 1e-06,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.3691275167785235,
      "val_f1": 0.3396381145066581,
      "val_precision": 0.5307383472232465,
      "val_recall": 0.3691275167785235,
      "test_accuracy": 0.34355828220858897,
      "test_f1": 0.28050047128470557,
      "test_precision": 0.38452624403544644,
      "test_recall": 0.34355828220858897,
      "learning_rate": 1e-06,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.3288590604026846,
      "val_f1": 0.2629044678103695,
      "val_precision": 0.23547869135253402,
      "val_recall": 0.3288590604026846,
      "test_accuracy": 0.34355828220858897,
      "test_f1": 0.26968372726972023,
      "test_precision": 0.22333999575076183,
      "test_recall": 0.34355828220858897,
      "learning_rate": 1e-06,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.2348993288590604,
      "val_f1": 0.14180494849105132,
      "val_precision": 0.10615636916995569,
      "val_recall": 0.2348993288590604,
      "test_accuracy": 0.1901840490797546,
      "test_f1": 0.12196304650795248,
      "test_precision": 0.09163706813044882,
      "test_recall": 0.1901840490797546,
      "learning_rate": 1e-07,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.2483221476510067,
      "val_f1": 0.1414356833224709,
      "val_precision": 0.2114599527294329,
      "val_recall": 0.2483221476510067,
      "test_accuracy": 0.18404907975460122,
      "test_f1": 0.0967455679378859,
      "test_precision": 0.11137342501380676,
      "test_recall": 0.18404907975460122,
      "learning_rate": 1e-07,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.26174496644295303,
      "val_f1": 0.12549968826786959,
      "val_precision": 0.13219162230965056,
      "val_recall": 0.26174496644295303,
      "test_accuracy": 0.15337423312883436,
      "test_f1": 0.04100915324300384,
      "test_precision": 0.023668863137165794,
      "test_recall": 0.15337423312883436,
      "learning_rate": 1e-07,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.2550335570469799,
      "val_f1": 0.19980827730580175,
      "val_precision": 0.29406738322315856,
      "val_recall": 0.2550335570469799,
      "test_accuracy": 0.2331288343558282,
      "test_f1": 0.17760966139201617,
      "test_precision": 0.2202377647614024,
      "test_recall": 0.2331288343558282,
      "learning_rate": 1e-07,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "hi",
      "val_accuracy": 0.19463087248322147,
      "val_f1": 0.13829000009697176,
      "val_precision": 0.11912875358550343,
      "val_recall": 0.19463087248322147,
      "test_accuracy": 0.10429447852760736,
      "test_f1": 0.06251660598637802,
      "test_precision": 0.056195514121792696,
      "test_recall": 0.10429447852760736,
      "learning_rate": 1e-07,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_hi_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.5272727272727272,
      "val_f1": 0.4903931953846872,
      "val_precision": 0.5199581497585932,
      "val_recall": 0.5272727272727272,
      "test_accuracy": 0.4594594594594595,
      "test_f1": 0.41023559620646993,
      "test_precision": 0.44169321585667676,
      "test_recall": 0.4594594594594595,
      "learning_rate": 1e-05,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.5212121212121212,
      "val_f1": 0.5061668447694561,
      "val_precision": 0.5720217721865688,
      "val_recall": 0.5212121212121212,
      "test_accuracy": 0.5297297297297298,
      "test_f1": 0.5172472023676763,
      "test_precision": 0.5446023715670869,
      "test_recall": 0.5297297297297298,
      "learning_rate": 1e-05,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.5515151515151515,
      "val_f1": 0.5502009636510955,
      "val_precision": 0.5815058479532164,
      "val_recall": 0.5515151515151515,
      "test_accuracy": 0.5405405405405406,
      "test_f1": 0.5411883481986575,
      "test_precision": 0.5565438165438166,
      "test_recall": 0.5405405405405406,
      "learning_rate": 1e-05,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.5393939393939394,
      "val_f1": 0.5397877733677592,
      "val_precision": 0.5757162157889301,
      "val_recall": 0.5393939393939394,
      "test_accuracy": 0.5135135135135135,
      "test_f1": 0.5103073454695082,
      "test_precision": 0.5307161529021994,
      "test_recall": 0.5135135135135135,
      "learning_rate": 1e-05,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.5393939393939394,
      "val_f1": 0.5231546927227507,
      "val_precision": 0.5635392062818114,
      "val_recall": 0.5393939393939394,
      "test_accuracy": 0.5513513513513514,
      "test_f1": 0.5389532959322865,
      "test_precision": 0.5666432666432666,
      "test_recall": 0.5513513513513514,
      "learning_rate": 1e-05,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.4303030303030303,
      "val_f1": 0.38864285012374483,
      "val_precision": 0.40851687745805393,
      "val_recall": 0.4303030303030303,
      "test_accuracy": 0.3837837837837838,
      "test_f1": 0.3468392805202965,
      "test_precision": 0.3247837485464604,
      "test_recall": 0.3837837837837838,
      "learning_rate": 1e-06,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.4121212121212121,
      "val_f1": 0.34696744329328605,
      "val_precision": 0.3974571681338599,
      "val_recall": 0.4121212121212121,
      "test_accuracy": 0.40540540540540543,
      "test_f1": 0.32381946287100566,
      "test_precision": 0.28099830071719284,
      "test_recall": 0.40540540540540543,
      "learning_rate": 1e-06,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.42424242424242425,
      "val_f1": 0.3507230599891831,
      "val_precision": 0.33710678210678213,
      "val_recall": 0.42424242424242425,
      "test_accuracy": 0.4756756756756757,
      "test_f1": 0.40418499157471655,
      "test_precision": 0.3884944034944035,
      "test_recall": 0.4756756756756757,
      "learning_rate": 1e-06,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.4666666666666667,
      "val_f1": 0.417676995243848,
      "val_precision": 0.49827852242738013,
      "val_recall": 0.4666666666666667,
      "test_accuracy": 0.4540540540540541,
      "test_f1": 0.411274103623443,
      "test_precision": 0.4016556677471259,
      "test_recall": 0.4540540540540541,
      "learning_rate": 1e-06,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.43636363636363634,
      "val_f1": 0.38916799522860124,
      "val_precision": 0.3563499777650721,
      "val_recall": 0.43636363636363634,
      "test_accuracy": 0.43243243243243246,
      "test_f1": 0.39562384372377296,
      "test_precision": 0.3673869731800766,
      "test_recall": 0.43243243243243246,
      "learning_rate": 1e-06,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.19393939393939394,
      "val_f1": 0.11043733117191144,
      "val_precision": 0.4365506125080593,
      "val_recall": 0.19393939393939394,
      "test_accuracy": 0.25405405405405407,
      "test_f1": 0.14607341841046134,
      "test_precision": 0.14481759089354027,
      "test_recall": 0.25405405405405407,
      "learning_rate": 1e-07,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.2909090909090909,
      "val_f1": 0.19249885650385423,
      "val_precision": 0.19987483530961792,
      "val_recall": 0.2909090909090909,
      "test_accuracy": 0.3081081081081081,
      "test_f1": 0.1854174174174174,
      "test_precision": 0.13669861722187304,
      "test_recall": 0.3081081081081081,
      "learning_rate": 1e-07,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.32727272727272727,
      "val_f1": 0.1771881707460397,
      "val_precision": 0.4108789760963674,
      "val_recall": 0.32727272727272727,
      "test_accuracy": 0.2702702702702703,
      "test_f1": 0.13816187464059804,
      "test_precision": 0.3540180180180181,
      "test_recall": 0.2702702702702703,
      "learning_rate": 1e-07,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.2787878787878788,
      "val_f1": 0.20707577312239425,
      "val_precision": 0.33538828910638013,
      "val_recall": 0.2787878787878788,
      "test_accuracy": 0.23243243243243245,
      "test_f1": 0.16718782559273357,
      "test_precision": 0.2663721413721414,
      "test_recall": 0.23243243243243245,
      "learning_rate": 1e-07,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "fr",
      "val_accuracy": 0.30303030303030304,
      "val_f1": 0.17018407723125253,
      "val_precision": 0.13208080808080808,
      "val_recall": 0.30303030303030304,
      "test_accuracy": 0.2594594594594595,
      "test_f1": 0.12517608517608517,
      "test_precision": 0.09287181918760865,
      "test_recall": 0.2594594594594595,
      "learning_rate": 1e-07,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_fr_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.48295454545454547,
      "val_f1": 0.4502198605173243,
      "val_precision": 0.47145263586713015,
      "val_recall": 0.48295454545454547,
      "test_accuracy": 0.4101123595505618,
      "test_f1": 0.3728786037874485,
      "test_precision": 0.39501079525272714,
      "test_recall": 0.4101123595505618,
      "learning_rate": 1e-05,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.5056818181818182,
      "val_f1": 0.48976159822703896,
      "val_precision": 0.4966112018551858,
      "val_recall": 0.5056818181818182,
      "test_accuracy": 0.449438202247191,
      "test_f1": 0.42580084712594124,
      "test_precision": 0.43871968057463545,
      "test_recall": 0.449438202247191,
      "learning_rate": 1e-05,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.48295454545454547,
      "val_f1": 0.45242783717312457,
      "val_precision": 0.4599080911904188,
      "val_recall": 0.48295454545454547,
      "test_accuracy": 0.449438202247191,
      "test_f1": 0.40539838339089007,
      "test_precision": 0.4213330292567713,
      "test_recall": 0.449438202247191,
      "learning_rate": 1e-05,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.4715909090909091,
      "val_f1": 0.3989059683872828,
      "val_precision": 0.3493216517315263,
      "val_recall": 0.4715909090909091,
      "test_accuracy": 0.42134831460674155,
      "test_f1": 0.3590039260322096,
      "test_precision": 0.3143148738101143,
      "test_recall": 0.42134831460674155,
      "learning_rate": 1e-05,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.5227272727272727,
      "val_f1": 0.4995021655211373,
      "val_precision": 0.5077550544262501,
      "val_recall": 0.5227272727272727,
      "test_accuracy": 0.4887640449438202,
      "test_f1": 0.4651356631086555,
      "test_precision": 0.47392041484441966,
      "test_recall": 0.4887640449438202,
      "learning_rate": 1e-05,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.4375,
      "val_f1": 0.3608974625275048,
      "val_precision": 0.31501889192678667,
      "val_recall": 0.4375,
      "test_accuracy": 0.43258426966292135,
      "test_f1": 0.360938847400228,
      "test_precision": 0.31567781922167376,
      "test_recall": 0.43258426966292135,
      "learning_rate": 1e-06,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.4431818181818182,
      "val_f1": 0.3694807393863998,
      "val_precision": 0.3324935834960034,
      "val_recall": 0.4431818181818182,
      "test_accuracy": 0.42696629213483145,
      "test_f1": 0.35628791301578366,
      "test_precision": 0.31280532486565704,
      "test_recall": 0.42696629213483145,
      "learning_rate": 1e-06,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.4375,
      "val_f1": 0.3596276805515277,
      "val_precision": 0.3312413930883358,
      "val_recall": 0.4375,
      "test_accuracy": 0.43258426966292135,
      "test_f1": 0.34531016391454006,
      "test_precision": 0.32154683605423534,
      "test_recall": 0.43258426966292135,
      "learning_rate": 1e-06,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.4375,
      "val_f1": 0.3745169779179818,
      "val_precision": 0.34542176573426575,
      "val_recall": 0.4375,
      "test_accuracy": 0.38202247191011235,
      "test_f1": 0.33086361659255564,
      "test_precision": 0.30208243531902257,
      "test_recall": 0.38202247191011235,
      "learning_rate": 1e-06,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.42045454545454547,
      "val_f1": 0.35294420777179397,
      "val_precision": 0.32902932254867995,
      "val_recall": 0.42045454545454547,
      "test_accuracy": 0.37640449438202245,
      "test_f1": 0.31440176156148747,
      "test_precision": 0.2884343135673709,
      "test_recall": 0.37640449438202245,
      "learning_rate": 1e-06,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed46"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.19886363636363635,
      "val_f1": 0.1011294388983731,
      "val_precision": 0.0839442815249267,
      "val_recall": 0.19886363636363635,
      "test_accuracy": 0.19662921348314608,
      "test_f1": 0.09818601900622996,
      "test_precision": 0.07596055629763494,
      "test_recall": 0.19662921348314608,
      "learning_rate": 1e-07,
      "seed": 42,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed42"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.23863636363636365,
      "val_f1": 0.15321872161364147,
      "val_precision": 0.19629702194357365,
      "val_recall": 0.23863636363636365,
      "test_accuracy": 0.25280898876404495,
      "test_f1": 0.16670079571180024,
      "test_precision": 0.24793376070506365,
      "test_recall": 0.25280898876404495,
      "learning_rate": 1e-07,
      "seed": 43,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed43"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.25,
      "val_f1": 0.20179311537372283,
      "val_precision": 0.1881315542746024,
      "val_recall": 0.25,
      "test_accuracy": 0.2303370786516854,
      "test_f1": 0.1710207254710535,
      "test_precision": 0.15988061714774293,
      "test_recall": 0.2303370786516854,
      "learning_rate": 1e-07,
      "seed": 44,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed44"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.25,
      "val_f1": 0.1771987322508673,
      "val_precision": 0.16416666666666666,
      "val_recall": 0.25,
      "test_accuracy": 0.2303370786516854,
      "test_f1": 0.16298863699054952,
      "test_precision": 0.14537185660781166,
      "test_recall": 0.2303370786516854,
      "learning_rate": 1e-07,
      "seed": 45,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed45"
    },
    {
      "model_name": "bert-base-uncased",
      "train_lang": "ru",
      "val_accuracy": 0.21022727272727273,
      "val_f1": 0.16177560882876754,
      "val_precision": 0.18558726652716426,
      "val_recall": 0.21022727272727273,
      "test_accuracy": 0.19662921348314608,
      "test_f1": 0.1408247370426078,
      "test_precision": 0.16382318154937908,
      "test_recall": 0.19662921348314608,
      "learning_rate": 1e-07,
      "seed": 46,
      "checkpoint_dir": "./results_bert-base-uncased_ru_seed46"
    }
  ]
}